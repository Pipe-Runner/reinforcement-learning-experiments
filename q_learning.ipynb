{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2eZ0ldKKC8iwDdRske43z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pipe-Runner/reinforcement-learning-experiments/blob/master/q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "1rOw56EQWNOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations"
      ],
      "metadata": {
        "id": "3RpNHFLzY72C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4t8r3bAbNby-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8e4a59-5899-41dd-8a7b-9cef5a7ed04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python-opengl is already the newest version (3.1.0+dfsg-2build1).\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt --quiet\n",
        "\n",
        "!sudo apt-get -qq update\n",
        "!apt install -qq python-opengl ffmpeg xvfb\n",
        "!pip3 install pyvirtualdisplay --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "TyJ9NpmqWrcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import random\n",
        "import imageio\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import pickle5 as pickle\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "ggc4RACkWCRX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Virtual Screen"
      ],
      "metadata": {
        "id": "HafOXZENXA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouO9JEduXC0H",
        "outputId": "5955b837-f50e-4194-d2c4-4fc48609966a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fc093847b20>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning (Frozen Lake v1 - Slippery )"
      ],
      "metadata": {
        "id": "00h36JYkYxGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Env "
      ],
      "metadata": {
        "id": "bUtptvRkXg2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=True, render_mode=\"rgb_array\")\n",
        "\n",
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Sample observation\", env.observation_space.sample())\n",
        "\n",
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-ZMNqmNXDJI",
        "outputId": "e7d2ad02-269c-4f58-9378-55eb41b9e0b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_____OBSERVATION SPACE_____ \n",
            "\n",
            "Observation Space Discrete(64)\n",
            "Sample observation 16\n",
            "\n",
            " _____ACTION SPACE_____ \n",
            "\n",
            "Action Space Shape 4\n",
            "Action Space Sample 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Q-Table"
      ],
      "metadata": {
        "id": "GOeVy6a9ZBK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = env.observation_space.n\n",
        "action_space = env.action_space.n\n",
        "\n",
        "def initialize_q_table(state_space, action_space):\n",
        "    Qtable = np.zeros((state_space, action_space))\n",
        "    return Qtable\n",
        "\n",
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "O88sgcZKXt51"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining policy"
      ],
      "metadata": {
        "id": "GgO5Y74AZd4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  # Exploitation: take the action with the highest state, action value\n",
        "  action = np.argmax(Qtable[state])\n",
        "\n",
        "  return action\n",
        "\n",
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  if np.random.random() > epsilon:\n",
        "    # exploit\n",
        "    return greedy_policy(Qtable, state)\n",
        "  else:\n",
        "    # explore\n",
        "    return env.action_space.sample()"
      ],
      "metadata": {
        "id": "G_7GsAlbZLpt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rcmjn7fbdSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}